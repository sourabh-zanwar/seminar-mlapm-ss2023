{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf92e8f-7aa4-462f-8c1e-1d599cba5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PyProM.src.data.Eventlog import Eventlog\n",
    "from object.object import Instance, Resource\n",
    "\n",
    "from prediction.model import UniLSTM, BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639d32cc-98c5-475d-a07e-d2600f97e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseOptimizer(object):\n",
    "\tdef __init__(self, *args, **kwargs):\n",
    "\t\tsuper(BaseOptimizer, self).__init__(*args, **kwargs)\n",
    "\t\tself.w_comp_time = list()\n",
    "\t\tself.pred_time = list()\n",
    "\n",
    "\tdef read_act_res_mat(self, path=\"./sample_data/new_resource_0806_1.csv\"):\n",
    "\t\t\"\"\"Read activity-resource matrix which specifies the processing time\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tpath -- file path\n",
    "\t\t\"\"\"\n",
    "\t\tact_res_mat = pd.read_csv(path)\n",
    "\t\tact_res_mat['Resource'] = 'Resource'+act_res_mat['Resource'].astype('str')\n",
    "\t\tact_res_mat = act_res_mat.set_index('Resource')\n",
    "\t\tact_res_mat = act_res_mat.to_dict()\n",
    "\t\treturn act_res_mat\n",
    "\n",
    "\tdef load_data(self,path):\n",
    "\t\t\"\"\"Load eventlog\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tpath -- file path\n",
    "\t\t\"\"\"\n",
    "\t\teventlog = Eventlog.from_txt(path, sep=',')\n",
    "\t\teventlog = eventlog.assign_caseid('CASE_ID')\n",
    "\t\teventlog = eventlog.assign_activity('Activity')\n",
    "\t\teventlog = eventlog.assign_resource('Resource')\n",
    "\t\tself.activities = list(set(eventlog['Activity']))\n",
    "\t\treturn eventlog\n",
    "\n",
    "\tdef load_real_data(self,path):\n",
    "\t\t\"\"\"Load real-life log (Requires modification according to the schema)\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tpath -- file path\n",
    "\t\t\"\"\"\n",
    "\t\teventlog = Eventlog.from_txt(path, sep=',')\n",
    "\t\teventlog = eventlog.assign_caseid('CASE_ID')\n",
    "\t\teventlog = eventlog.assign_activity('Activity')\n",
    "\t\teventlog['Resource'] = eventlog['Resource'].astype(int)\n",
    "\t\teventlog = eventlog.assign_resource('Resource')\n",
    "\t\teventlog = eventlog.assign_timestamp(name='StartTimestamp', new_name='StartTimestamp', _format = '%Y.%m.%d %H:%M:%S', errors='raise')\n",
    "\n",
    "\t\tdef to_minute(x):\n",
    "\t\t\tt = x.time()\n",
    "\t\t\tminutes = t.hour * 60 + t.minute\n",
    "\t\t\treturn minutes\n",
    "\n",
    "\t\teventlog['Start'] = eventlog['StartTimestamp'].apply(to_minute)\n",
    "\t\treturn eventlog\n",
    "\n",
    "\tdef initialize_real_instance(self, eventlog):\n",
    "\t\t\"\"\"Initialize real instance\n",
    "\t\tDifference between test and real instance\n",
    "\t\t1. Real - using date info.\n",
    "\t\t2. Real - release time is set to the appearing time of an instance\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\teventlog -- test log\n",
    "\t\t\"\"\"\n",
    "\t\tinstance_set = list()\n",
    "\t\tactivity_trace = eventlog.get_event_trace(workers=4, value='Activity')\n",
    "\t\tresource_trace = eventlog.get_event_trace(4,'Resource')\n",
    "\t\t#eventlog['StartDate'] = pd.to_datetime(eventlog[\"StartDate\"], format='%Y.%m.%d')\n",
    "\t\tdate_trace = eventlog.get_event_trace(workers=4, value='StartDate')\n",
    "\t\ttime_trace = eventlog.get_event_trace(workers=4, value='Start')\n",
    "\t\tdur_trace = eventlog.get_event_trace(workers=4, value='Duration')\n",
    "\t\tweight_trace = eventlog.get_event_trace(workers=4, value='weight')\n",
    "\t\t#target_date=pd.to_datetime(self.date)\n",
    "\n",
    "\t\tfor case in date_trace:\n",
    "\t\t\tfor j, time in enumerate(date_trace[case]):\n",
    "\t\t\t\tif time >= self.date:\n",
    "\t\t\t\t\tinitial_index =j-1\n",
    "\t\t\t\t\trelease_time = time_trace[case][j]\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tweight = min(weight_trace[case])\n",
    "\t\t\tinstance = Instance(name=case, weight=weight, release_time=release_time, act_sequence=activity_trace[case], res_sequence=resource_trace[case],dur_sequence=dur_trace[case], initial_index=initial_index)\n",
    "\t\t\tinstance_set.append(instance)\n",
    "\n",
    "\t\treturn instance_set\n",
    "\n",
    "\tdef initialize_test_instance(self, eventlog):\n",
    "\t\t\"\"\"Initialize test instance\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\teventlog -- test log\n",
    "\t\t\"\"\"\n",
    "\t\tinstance_set = list()\n",
    "\t\tactivity_trace = eventlog.get_event_trace(workers=4, value='Activity')\n",
    "\t\tresource_trace = eventlog.get_event_trace(4,'Resource')\n",
    "\t\ttime_trace = eventlog.get_event_trace(workers=4, value='Start')\n",
    "\t\tdur_trace = eventlog.get_event_trace(workers=4, value='Duration')\n",
    "\t\tweight_trace = eventlog.get_event_trace(workers=4, value='weight')\n",
    "\t\tfor case in activity_trace:\n",
    "\t\t\trelease_time = min(time_trace[case])\n",
    "\t\t\t#release_time = 0\n",
    "\t\t\tweight = min(weight_trace[case])\n",
    "\t\t\tinstance = Instance(name=case, weight=weight, release_time=release_time, act_sequence=activity_trace[case], res_sequence=resource_trace[case],dur_sequence=dur_trace[case])\n",
    "\t\t\tinstance_set.append(instance)\n",
    "\t\treturn instance_set\n",
    "\n",
    "\tdef initialize_real_resource(self, test_log):\n",
    "\t\t\"\"\"Initialize real instance\n",
    "\t\tNo difference at the moment\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\ttest_log -- test log\n",
    "\t\t\"\"\"\n",
    "\t\tresource_set = list()\n",
    "\t\tresource_list = sorted(list(test_log.get_resources()))\n",
    "\t\tfor res in resource_list:\n",
    "\t\t\tact_list = list(test_log.loc[test_log['Resource']==res,'Activity'].unique())\n",
    "\t\t\tresource = Resource(res, act_list)\n",
    "\t\t\tresource_set.append(resource)\n",
    "\t\treturn resource_set\n",
    "\n",
    "\tdef initialize_test_resource(self, eventlog):\n",
    "\t\t\"\"\"Initialize test resource\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\teventlog -- test log\n",
    "\t\t\"\"\"\n",
    "\t\tresource_set = list()\n",
    "\t\tresource_list = sorted(list(eventlog.get_resources()))\n",
    "\t\tfor res in resource_list:\n",
    "\t\t\tact_list = list(eventlog.loc[eventlog['Resource']==res,'Activity'].unique())\n",
    "\t\t\tresource = Resource(res, act_list)\n",
    "\t\t\tresource_set.append(resource)\n",
    "\t\treturn resource_set\n",
    "\n",
    "\tdef set_basic_info(self, eventlog):\n",
    "\t\t\"\"\"set basic info. for instances\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\teventlog -- test log\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# To be aligned with the entire log, we load the information generated from entire log\n",
    "\t\tif self.mode == 'test':\n",
    "\t\t\twith open('./prediction/checkpoints/traininglog_0806_1.csv_activities.pkl', 'rb') as f:\n",
    "\t\t\t\tactivities = pickle.load(f)\n",
    "\t\t\twith open('./prediction/checkpoints/traininglog_0806_1.csv_resources.pkl', 'rb') as f:\n",
    "\t\t\t\tresources = pickle.load(f)\n",
    "\t\telse:\n",
    "\t\t\twith open('./prediction/checkpoints/modi_BPI_2012_dropna_filter_act.csv_activities.pkl', 'rb') as f:\n",
    "\t\t\t\tactivities = pickle.load(f)\n",
    "\t\t\twith open('./prediction/checkpoints/modi_BPI_2012_dropna_filter_act.csv_resources.pkl', 'rb') as f:\n",
    "\t\t\t\tresources = pickle.load(f)\n",
    "\t\tact_char_to_int = dict((str(c), i) for i, c in enumerate(activities))\n",
    "\t\tact_int_to_char = dict((i, str(c)) for i, c in enumerate(activities))\n",
    "\t\tres_char_to_int = dict((str(c), i) for i, c in enumerate(resources))\n",
    "\t\tres_int_to_char = dict((i, str(c)) for i, c in enumerate(resources))\n",
    "\n",
    "\t\t# for contextual information\n",
    "\t\tself.queue = OrderedDict()\n",
    "\t\tfor act in activities:\n",
    "\t\t\tif act != '!':\n",
    "\t\t\t\tself.queue[act] = 0\n",
    "\n",
    "\t\t# maxlen information\n",
    "\t\tactivity_trace = eventlog.get_event_trace(4,'Activity')\n",
    "\t\ttrace_len = [len(x) for x in activity_trace.values()]\n",
    "\t\tmaxlen = max(trace_len)\n",
    "\n",
    "\t\t# set info.\n",
    "\t\tInstance.set_activity_list(activities)\n",
    "\t\tInstance.set_resource_list(resources)\n",
    "\t\tInstance.set_act_char_to_int(act_char_to_int)\n",
    "\t\tInstance.set_act_int_to_char(act_int_to_char)\n",
    "\t\tInstance.set_res_char_to_int(res_char_to_int)\n",
    "\t\tInstance.set_res_int_to_char(res_int_to_char)\n",
    "\t\tInstance.set_maxlen(maxlen)\n",
    "\n",
    "\tdef load_model(self, checkpoint_dir, model_name, loss):\n",
    "\t\t\"\"\"load prediction model\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tcheckpoint_dir -- directory path\n",
    "\t\tmodel_name -- decide which model to load\n",
    "\t\t\"\"\"\n",
    "\t\tmodel = UniLSTM()\n",
    "\t\tmodel.load(checkpoint_dir, model_name, loss, compiles=False)\n",
    "\t\treturn model\n",
    "\n",
    "\tdef prepare_test(self, test_path, res_info_path):\n",
    "\t\t\"\"\"prepare experiment on the artificial log\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\ttest_path -- path to the test log\n",
    "\t\tres_info_path -- path to the activity-resource processing time\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tcheckpoint_dir = './prediction/checkpoints/'\n",
    "\t\tmodelname_next_act = 'traininglog_0806_1.csv' + 'next_activity'\n",
    "\t\tmodelname_next_time = 'traininglog_0806_1.csv' + 'next_timestamp'\n",
    "\n",
    "\t\t# load prediction model\n",
    "\t\tmodel_next_act = self.load_model(checkpoint_dir, modelname_next_act)\n",
    "\t\tmodel_next_time = self.load_model(checkpoint_dir, modelname_next_time)\n",
    "\n",
    "\t\t# set prediction model\n",
    "\t\tInstance.set_model_next_act(model_next_act)\n",
    "\t\tInstance.set_model_next_time(model_next_time)\n",
    "\n",
    "\t\t# load log\n",
    "\t\ttest_log = self.load_data(path=test_path)\n",
    "\n",
    "\t\t#initialize resource set\n",
    "\t\tresource_set = self.initialize_test_resource(test_log)\n",
    "\n",
    "\t\t#create act-res matrix\n",
    "\t\tself.act_res_mat = self.read_act_res_mat(res_info_path)\n",
    "\n",
    "\t\t# initialize instance set\n",
    "\t\tinstance_set = self.initialize_test_instance(test_log)\n",
    "\n",
    "\t\t#Set attributes of instance -> to be used to gernerate input for prediction\n",
    "\t\tself.set_basic_info(test_log)\n",
    "\n",
    "\t\treturn resource_set, instance_set\n",
    "\n",
    "\tdef prepare_real(self, test_path, org_log_path):\n",
    "\t\t\"\"\"prepare experiment on the real log\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\ttest_path -- path to the test log\n",
    "\t\torg_log_path -- path to the entire log\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tcheckpoint_dir = './prediction/checkpoints/'\n",
    "\t\tmodelname_next_act = 'modi_BPI_2012_dropna_filter_act.csv' + 'next_activity'\n",
    "\t\tmodelname_next_time = 'modi_BPI_2012_dropna_filter_act.csv' + 'next_timestamp'\n",
    "\n",
    "\t\t# load prediction model\n",
    "\t\tmodel_next_act = self.load_model(checkpoint_dir, modelname_next_act, loss = 'categorical_crossentropy')\n",
    "\t\tmodel_next_time = self.load_model(checkpoint_dir, modelname_next_time, loss = 'mae')\n",
    "\n",
    "\t\t# set prediction model\n",
    "\t\tInstance.set_model_next_act(model_next_act)\n",
    "\t\tInstance.set_model_next_time(model_next_time)\n",
    "\n",
    "\t\t# load eventlog\n",
    "\t\teventlog = self.load_real_data(path=org_log_path)\n",
    "\n",
    "\t\t# load test log\n",
    "\t\ttest_log = self.load_real_data(path=test_path)\n",
    "\t\tself.num_cases = len(set(test_log['CASE_ID']))\n",
    "\t\tself.avg_weight = test_log['weight'].mean()\n",
    "\n",
    "\t\t#no act-res matrix\n",
    "\t\tself.act_res_mat = None\n",
    "\n",
    "\t\t# initialize instance set\n",
    "\t\tinstance_set = self.initialize_real_instance(test_log)\n",
    "\n",
    "\t\t#initialize resource set\n",
    "\t\tresource_set = self.initialize_real_resource(test_log)\n",
    "\n",
    "\t\t#Set attributes of instance -> to be used to gernerate input for prediction\n",
    "\t\tself.set_basic_info(eventlog)\n",
    "\n",
    "\t\treturn resource_set, instance_set\n",
    "\n",
    "\n",
    "\tdef update_ongoing_instances(self, instance_set, ongoing_instance, t):\n",
    "\t\t\"\"\"include released instances to the ongoing instance set\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tinstance_set -- all instances for resource allocation\n",
    "\t\tongoing_instance -- ongoing instance set\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in instance_set:\n",
    "\t\t\tif i.get_release_time() == t:\n",
    "\t\t\t\tongoing_instance.append(i)\n",
    "\t\treturn ongoing_instance\n",
    "\n",
    "\tdef update_object(self, ongoing_instance, resource_set, t):\n",
    "\t\t\"\"\"create the bipartite graph with the prediction results\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tongoing_instance -- ongoing instance set\n",
    "\t\tresource_set -- all resources for resource allocation\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\t# if resource is free, set the status to 'True'\n",
    "\t\tfor j in resource_set:\n",
    "\t\t\tif j.get_next_actual_ts() == t:\n",
    "\t\t\t\tj.set_status(True)\n",
    "\n",
    "\t\t# if resource is free, set the status to 'True'\n",
    "\t\tfor i in ongoing_instance:\n",
    "\t\t\tif i.get_next_actual_ts() == t:\n",
    "\t\t\t\tcur_actual_act = i.get_cur_actual_act()\n",
    "\t\t\t\tif cur_actual_act != False:\n",
    "\t\t\t\t\tself.queue[cur_actual_act] -= 1\n",
    "\t\t\t\ti.set_status(True)\n",
    "\t\t\telif i.get_next_actual_ts() < t:\n",
    "\t\t\t\ti.update_weight()\n",
    "\n",
    "\t\t# generate bipartite graph\n",
    "\t\tready_instance = [x for x in ongoing_instance if x.get_status()==True]\n",
    "\t\tready_resource = [x for x in resource_set if x.get_status()==True]\n",
    "\t\tG = nx.DiGraph()\n",
    "\t\tfor i in ready_instance:\n",
    "\t\t\tactual_act = i.get_next_actual_act()\n",
    "\t\t\tfor j in ready_resource:\n",
    "\t\t\t\tif actual_act in j.get_skills():\n",
    "\t\t\t\t\tG.add_edge('s',i, capacity=1)\n",
    "\t\t\t\t\tG.add_edge(j,'t',capacity=1)\n",
    "\t\t\t\t\tweight = i.get_weight()\n",
    "\t\t\t\t\tcost = weight * (-1)\n",
    "\t\t\t\t\tG.add_edge(i,j,weight=cost,capacity=1)\n",
    "\t\treturn G\n",
    "\n",
    "\n",
    "\tdef update_plan(self, G, t):\n",
    "\t\t\"\"\"solve the min-cost max-flow algorithm to find an optimal schedule\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tG -- bipartite graph\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\tnodes=G.nodes()\n",
    "\t\tif len(nodes)!=0:\n",
    "\t\t\tM = nx.max_flow_min_cost(G, 's', 't')\n",
    "\t\telse:\n",
    "\t\t\tM=False\n",
    "\t\treturn M\n",
    "\n",
    "\n",
    "\tdef execute_plan(self, ongoing_instance, resource_set, M, t):\n",
    "\t\t\"\"\"execute the resource allocation and update the situation accordingly.\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tongoing_instance -- ongoing instance set\n",
    "\t\tresource_set -- all resources for resource allocation\n",
    "\t\tM -- optimal schedule\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tready_instance = [x for x in ongoing_instance if x.get_status()==True]\n",
    "\t\tready_resource = [x for x in resource_set if x.get_status()==True]\n",
    "\t\tif M!=False:\n",
    "\t\t\tfor i in M:\n",
    "\t\t\t\tif i in ready_instance:\n",
    "\t\t\t\t\tfor j, val in M[i].items():\n",
    "\t\t\t\t\t\t# check if there is a flow\n",
    "\t\t\t\t\t\tif val==1 and j in ready_resource:\n",
    "\t\t\t\t\t\t\tcur_pred_dur, cur_time_uncertainty = i.predict_next_time(self.queue, context=True, pred_act=i.get_next_actual_act(), resource=j.get_name())\n",
    "\t\t\t\t\t\t\ti.set_pred_act_dur(j, cur_pred_dur, cur_time_uncertainty)\n",
    "\t\t\t\t\t\t\ti.update_actuals(t, j, self.mode, self.act_res_mat,self.queue)\n",
    "\n",
    "\t\t\t\t\t\t\tj.set_next_pred_ts(i.get_next_pred_ts())\n",
    "\t\t\t\t\t\t\tj.set_next_ts_uncertainty(i.get_next_ts_uncertainty(j))\n",
    "\t\t\t\t\t\t\tj.set_next_actual_ts(i.get_next_actual_ts())\n",
    "\t\t\t\t\t\t\tj.set_status(False)\n",
    "\n",
    "\t\t\t\t\t\t\t# update contextual information\n",
    "\t\t\t\t\t\t\tcur_actual_act = i.get_cur_actual_act()\n",
    "\t\t\t\t\t\t\tif cur_actual_act != False:\n",
    "\t\t\t\t\t\t\t\tself.queue[cur_actual_act] += 1\n",
    "\n",
    "\t\t\t\t\t\t\ti.clear_pred_act_dur()\n",
    "\t\t\t\t\t\t\t# to implement FIFO rule\n",
    "\t\t\t\t\t\t\ti.reset_weight()\n",
    "\n",
    "\n",
    "\tdef update_completes(self, completes, ongoing_instance, t):\n",
    "\t\t\"\"\"check if instance finishes its operation\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tcompletes -- set of complete instances\n",
    "\t\tongoing_instance -- ongoing instance set\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in ongoing_instance:\n",
    "\t\t\tfinished = i.check_finished(t)\n",
    "\t\t\tif finished==True:\n",
    "\t\t\t\tcur_actual_act = i.get_cur_actual_act()\n",
    "\t\t\t\tself.queue[cur_actual_act] -= 1\n",
    "\t\t\t\ti.set_weighted_comp()\n",
    "\t\t\t\tongoing_instance.remove(i)\n",
    "\t\t\t\tcompletes.append(i)\n",
    "\t\t\t\tself.w_comp_time.append(i.get_weighted_comp())\n",
    "\t\t\t\tself.pred_time += i.get_pred_time_list()\n",
    "\t\t\t\t\"\"\"\n",
    "\t\t\t\twith open(\"./exp_result/exp_7.txt\", \"a\") as f:\n",
    "\t\t\t\t\tf.write(\"{}-{}: start at {}, end at {}, weighted_comp = {} \\n\".format(i.get_name(), i.get_weight(), i.release_time, i.get_next_actual_ts(), i.get_weighted_comp()))\n",
    "\t\t\t\t\"\"\"\n",
    "\t\treturn completes\n",
    "\n",
    "\tdef main(self, test_path, mode, date, exp_name, **kwargs):\n",
    "\t\ttime1 = time.time()\n",
    "\t\tt=0\n",
    "\t\t#initialize\n",
    "\t\tongoing_instance = list()\n",
    "\t\tcompletes = list()\n",
    "\t\tself.mode = mode\n",
    "\t\tself.date = date\n",
    "\n",
    "\t\tif mode=='test':\n",
    "\t\t\tif \"res_info_path\" in kwargs:\n",
    "\t\t\t\tres_info_path = kwargs['res_info_path']\n",
    "\t\t\telse:\n",
    "\t\t\t\traise AttributeError(\"Resource Information is required\")\n",
    "\t\t\tresource_set, instance_set = self.prepare_test(test_path, res_info_path)\n",
    "\n",
    "\t\telif mode == 'real':\n",
    "\t\t\tif 'org_log_path' in kwargs:\n",
    "\t\t\t\torg_log_path = kwargs['org_log_path']\n",
    "\t\t\telse:\n",
    "\t\t\t\traise AttributeError(\"no org_log_path given.\")\n",
    "\t\t\tresource_set, instance_set = self.prepare_real(test_path, org_log_path )\n",
    "\t\t\t#print(\"num resource:{}\".format(len(resource_set)))\n",
    "\n",
    "\t\telse:\n",
    "\t\t\traise AttributeError('Optimization mode should be given.')\n",
    "\n",
    "\n",
    "\t\twhile len(instance_set) != len(completes):\n",
    "\t\t\t#print(\"{} begins\".format(t))\n",
    "\t\t\t#ongoing instance를 추가\n",
    "\t\t\tongoing_instance = self.update_ongoing_instances(instance_set, ongoing_instance, t)\n",
    "\t\t\t##print('current ongoing instance: {}'.format(len(ongoing_instance)))\n",
    "\t\t\tG = self.update_object(ongoing_instance, resource_set,t)\n",
    "\t\t\t##print('current cand instance and resource: {}, {}'.format(cand_instance, cand_resource))\n",
    "\t\t\tM = self.update_plan(G,t)\n",
    "\t\t\t##print('current matching: {}'.format(M))\n",
    "\t\t\tself.execute_plan(ongoing_instance, resource_set, M, t)\n",
    "\t\t\tcompletes = self.update_completes(completes, ongoing_instance, t)\n",
    "\t\t\t#print('current completes: {}'.format(len(completes)))\n",
    "\t\t\tt+=1\n",
    "\t\ttime2 = time.time()\n",
    "\t\ttotal_weighted_sum = sum(self.w_comp_time)\n",
    "\t\ttotal_pred_time = sum(self.pred_time)\n",
    "\t\ttotal_computation_time = (time2-time1)\n",
    "\t\ttotal_opti_time = total_computation_time - total_pred_time\n",
    "\n",
    "\t\t#print(\"total weighted sum: {}\".format(total_weighted_sum))\n",
    "\t\t#print('suggested algorithm took {:.1f} s'.format(total_computation_time))\n",
    "\t\tif self.mode=='real':\n",
    "\t\t\twith open(\"./exp_result/{}.txt\".format(exp_name), \"w\") as f:\n",
    "\t\t\t\t#f.write(\"Baseline: {}, num_cases: {}, avg_weight: {} \\n {}, {} \\n\".format(test_path, self.num_cases, self.avg_weight, total_weighted_sum, total_computation_time))\n",
    "\t\t\t\tf.write(f\"Baseline:\\nTotal Weighted Sum: = {total_weighted_sum}\\nTotal Computation Time = {total_computation_time}\\nPrediction Time = {total_pred_time}\\nOptimization Time = {total_opti_time}\")\n",
    "\t\telse:\n",
    "\t\t\twith open(\"./exp_result/{}.txt\".format(exp_name), \"a\") as f:\n",
    "\t\t\t\t#f.write(\"Baseline: {} \\n {}, {} \\n\".format(test_path, total_weighted_sum, total_computation_time))\n",
    "\t\t\t\tf.write(f\"Baseline:\\nWeighted Completion Time = {total_weighted_sum}\\nComputation Time = {total_computation_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059b17ad-db14-4797-8fed-157461fc47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2012-03-10']\n",
    "org_log_path = 'sample_data/real/modi_BPI_2012_dropna_filter_act.csv'\n",
    "alpha = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19341b43-fc5d-409c-bf3a-64f35c70289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]2023-07-03 12:53:25.909338: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@timefn: assign_caseid took 0.013997077941894531 seconds\n",
      "@timefn: assign_activity took 0.007562875747680664 seconds\n",
      "@timefn: assign_resource took 0.018788814544677734 seconds\n",
      "%Y.%m.%d %H:%M:%S\n",
      "@timefn: assign_timestamp took 0.012339353561401367 seconds\n",
      "@timefn: assign_caseid took 0.0009222030639648438 seconds\n",
      "@timefn: assign_activity took 0.0004906654357910156 seconds\n",
      "@timefn: assign_resource took 0.000492095947265625 seconds\n",
      "%Y.%m.%d %H:%M:%S\n",
      "@timefn: assign_timestamp took 0.0014646053314208984 seconds\n",
      "8669 exceed the limit\n",
      "8557 exceed the limit\n",
      "8805 exceed the limit\n",
      "8094 exceed the limit\n",
      "9104 exceed the limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:10<00:00, 70.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for date in tqdm(dates):\n",
    "    Opt = BaseOptimizer()\n",
    "    testp =  f\"sample_data/real/modi_BPI_2012_{date}.csv\"\n",
    "    exp_name = 'baseline_' + date\n",
    "    Opt.main(org_log_path = org_log_path, test_path  =testp, mode='real', alpha=alpha, beta=alpha, precision=0.0, date=date, exp_name=exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6e18f-2451-4c12-bc8e-7303f700e521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
