{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a42fe2-a703-4827-bdb9-d56d147add33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define model Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d4b23-4617-4387-9499-0b73552ee685",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb5d94-9131-45f2-b99e-b9e8cf67e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e1eca9-f35a-4f7e-8b7b-b9b4606c6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "from scipy.special import logsumexp\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.regularizers import l2\n",
    "from keras import Input\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Bidirectional\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302e52ec-b8f1-437b-babf-c7e969176c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e7497-fc54-4e23-b299-8d1223c6f5b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LSTM (Unidirectional)\n",
    "\n",
    "This is the original implementation as used in the paper\n",
    "\n",
    "we rename the model from \"net\" to \"UniLSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19967901-d1d1-4b2a-9758-2467570d2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniLSTM:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, X_train_ctx, y_train, regression, loss, n_epochs = 100,\n",
    "        normalize = False, y_normalize=False, tau = 1.0, dropout = 0.05, batch_size= 128, context=True, num_folds=10, model_name='predictor', checkpoint_dir='./checkpoints/'):\n",
    "\n",
    "        \"\"\"\n",
    "            Constructor for the class implementing a Bayesian neural network\n",
    "            trained with the probabilistic back propagation method.\n",
    "            @param X_train      Matrix with the features for the training data.\n",
    "            @param y_train      Vector with the target variables for the\n",
    "                                training data.\n",
    "            @param n_epochs     Numer of epochs for which to train the\n",
    "                                network. The recommended value 40 should be\n",
    "                                enough.\n",
    "            @param normalize    Whether to normalize the input features. This\n",
    "                                is recommended unles the input vector is for\n",
    "                                example formed by binary features (a\n",
    "                                fingerprint). In that case we do not recommend\n",
    "                                to normalize the features.\n",
    "            @param tau          Tau value used for regularization\n",
    "            @param dropout      Dropout rate for all the dropout layers in the\n",
    "                                network.\n",
    "        \"\"\"\n",
    "\n",
    "        # We normalize the training data to have zero mean and unit standard\n",
    "        # deviation in the training set if necessary\n",
    "        \"\"\"\n",
    "        if normalize:\n",
    "            self.std_X_train_ctx = np.std(X_train_ctx, 0)\n",
    "            self.std_X_train_ctx[ self.X_train_ctx == 0 ] = 1\n",
    "            self.mean_X_train_ctx = np.mean(X_train_ctx, 0)\n",
    "        else:\n",
    "            self.std_X_train_ctx = np.ones(X_train_ctx.shape[ 1 ])\n",
    "            self.mean_X_train_ctx = np.zeros(X_train_ctx.shape[ 1 ])\n",
    "\n",
    "        X_train_ctx = (X_train_ctx - np.full(X_train_ctx.shape, self.mean_X_train_ctx)) / \\\n",
    "            np.full(X_train_ctx.shape, self.std_X_train_ctx)\n",
    "        \"\"\"\n",
    "        if y_normalize:\n",
    "            self.mean_y_train = np.mean(y_train)\n",
    "            self.std_y_train = np.std(y_train)\n",
    "\n",
    "            y_train_normalized = (y_train - self.mean_y_train) / self.std_y_train\n",
    "            y_train_normalized = np.array(y_train_normalized, ndmin = 2).T\n",
    "        else:\n",
    "            if len(y_train.shape)==1:\n",
    "                y_train_normalized = np.array(y_train, ndmin = 2).T\n",
    "            else:\n",
    "                y_train_normalized = y_train\n",
    "\n",
    "\n",
    "        # We construct the network\n",
    "        N = X_train.shape[0]\n",
    "        batch_size = batch_size\n",
    "        num_folds = num_folds\n",
    "\n",
    "        inputs = Input(shape=(X_train.shape[1], X_train.shape[2]), name='main_input')\n",
    "        inter = Dropout(dropout)(inputs, training=True)\n",
    "        inter = LSTM(30, recurrent_dropout=dropout, return_sequences=True)(inputs, training=True)\n",
    "        inter = Dropout(dropout)(inter, training=True)\n",
    "        inter = LSTM(30)(inter, training=True)\n",
    "        inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "        if context==True:\n",
    "            context_shape = X_train_ctx.shape\n",
    "            auxiliary_input = Input(shape=(context_shape[1],), name='aux_input')\n",
    "            aux_inter = Dropout(dropout)(auxiliary_input, training=True)\n",
    "\n",
    "            inter = keras.layers.concatenate([inter, aux_inter])\n",
    "            inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1], )(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=[inputs,auxiliary_input], outputs=outputs)\n",
    "\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = keras.callbacks.ModelCheckpoint('%smodel_%s_.h5' % (checkpoint_dir, model_name), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "            lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit([X_train,X_train_ctx], y_train_normalized, batch_size=batch_size, epochs=n_epochs, verbose=2, validation_split=1/num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "        else:\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1], )(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = keras.callbacks.ModelCheckpoint('%smodel_%s_.h5' % (checkpoint_dir, model_name), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "            lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train_normalized, batch_size=batch_size, epochs=n_epochs, verbose=2, validation_split=1/num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "\n",
    "        self.model = model\n",
    "        self.tau = tau\n",
    "        self.running_time = time.time() - start_time\n",
    "\n",
    "        # We are done!\n",
    "\n",
    "    def load(self, checkpoint_dir, model_name, loss, compiles):\n",
    "        if not compiles:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name), compile=compiles)\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "        else:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name))\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, X_test, X_test_ctx=None, context=True):\n",
    "\n",
    "        \"\"\"\n",
    "            Function for making predictions with the Bayesian neural network.\n",
    "            @param X_test   The matrix of features for the test data\n",
    "\n",
    "\n",
    "            @return m       The predictive mean for the test target variables.\n",
    "            @return v       The predictive variance for the test target\n",
    "                            variables.\n",
    "            @return v_noise The estimated variance for the additive noise.\n",
    "        \"\"\"\n",
    "\n",
    "        X_test = np.array(X_test, ndmin = 3)\n",
    "\n",
    "\n",
    "        # We normalize the test set\n",
    "        #X_test_ctx = (X_test_ctx - np.full(X_test_ctx.shape, self.mean_X_train_ctx)) /    np.full(X_test_ctx.shape, self.std_X_train_ctx)\n",
    "\n",
    "        # We compute the predictive mean and variance for the target variables\n",
    "        # of the test data\n",
    "\n",
    "        model = self.model\n",
    "        \"\"\"\n",
    "        standard_pred = model.predict([X_test, X_test_ctx], batch_size=500, verbose=1)\n",
    "        standard_pred = standard_pred * self.std_y_train + self.mean_y_train\n",
    "        rmse_standard_pred = np.mean((y_test.squeeze() - standard_pred.squeeze())**2.)**0.5\n",
    "        \"\"\"\n",
    "        T = 10\n",
    "        #if context==True:\n",
    "        X_test_ctx = np.array(X_test_ctx, ndmin=2)\n",
    "        Yt_hat = np.array([model.predict([X_test, X_test_ctx], batch_size=1, verbose=0) for _ in range(T)])\n",
    "        #else:\n",
    "        #    Yt_hat = np.array([model.predict(X_test, batch_size=1, verbose=0) for _ in range(T)])\n",
    "        #Yt_hat = Yt_hat * self.std_y_train + self.mean_y_train\n",
    "        regression=False\n",
    "        if regression:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = np.std(Yt_hat, 0)\n",
    "        else:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = list()\n",
    "            for i in range(Yt_hat.shape[2]):\n",
    "                MC_uncertainty.append(np.std(Yt_hat[:,:,i].squeeze(),0))\n",
    "        #rmse = np.mean((y_test.squeeze() - MC_pred.squeeze())**2.)**0.5\n",
    "\n",
    "        # We compute the test log-likelihood\n",
    "        \"\"\"\n",
    "        ll = (logsumexp(-0.5 * self.tau * (y_test[None] - Yt_hat)**2., 0) - np.log(T)\n",
    "            - 0.5*np.log(2*np.pi) + 0.5*np.log(self.tau))\n",
    "        test_ll = np.mean(ll)\n",
    "        \"\"\"\n",
    "        # We are done!\n",
    "        return MC_pred, MC_uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76081b-59fd-488c-96a0-c8de2c700a9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Bi-directional LSTM\n",
    "\n",
    "The code for this is based on the original code, I have only changed the part where models are described.\n",
    "Also, a bug was fixed in model.save and model.load as well as in predict function (for with contextual information part)\n",
    "\n",
    "We name the model \"BiLSTM\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f23eb1-4857-402d-8aae-d613447916e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, X_train_ctx, y_train, regression, loss, n_epochs=100,\n",
    "              normalize=False, y_normalize=False, tau=1.0, dropout=0.05, batch_size=128, context=True,\n",
    "              num_folds=10, model_name='predictor', checkpoint_dir='./checkpoints/'):\n",
    "\n",
    "        if y_normalize:\n",
    "            self.mean_y_train = np.mean(y_train)\n",
    "            self.std_y_train = np.std(y_train)\n",
    "\n",
    "            y_train_normalized = (y_train - self.mean_y_train) / self.std_y_train\n",
    "            y_train_normalized = np.array(y_train_normalized, ndmin=2).T\n",
    "        else:\n",
    "            if len(y_train.shape) == 1:\n",
    "                y_train_normalized = np.array(y_train, ndmin=2).T\n",
    "            else:\n",
    "                y_train_normalized = y_train\n",
    "\n",
    "        # We construct the network\n",
    "        N = X_train.shape[0]\n",
    "        batch_size = batch_size\n",
    "        num_folds = num_folds\n",
    "\n",
    "        inputs = Input(shape=(X_train.shape[1], X_train.shape[2]), name='main_input')\n",
    "        inter = Dropout(dropout)(inputs, training=True)\n",
    "        inter = Bidirectional(LSTM(64, recurrent_dropout=dropout, return_sequences=True))(inter, training=True)\n",
    "        inter = Dropout(dropout)(inter, training=True)\n",
    "        inter = Bidirectional(LSTM(64))(inter, training=True)\n",
    "        inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "        if context == True:\n",
    "            context_shape = X_train_ctx.shape\n",
    "            auxiliary_input = Input(shape=(context_shape[1],), name='aux_input')\n",
    "            aux_inter = Dropout(dropout)(auxiliary_input, training=True)\n",
    "\n",
    "            inter = keras.layers.concatenate([inter, aux_inter])\n",
    "            inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1])(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=[inputs, auxiliary_input], outputs=outputs)\n",
    "\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = keras.callbacks.ModelCheckpoint('%smodel_%s_.h5' % (checkpoint_dir, model_name),\n",
    "                                                               monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                                               save_weights_only=False, mode='auto')\n",
    "            lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0,\n",
    "                                                            mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit([X_train, X_train_ctx], y_train_normalized, batch_size=batch_size, epochs=n_epochs,\n",
    "                      verbose=2, validation_split=1 / num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "        else:\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1])(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = keras.callbacks.ModelCheckpoint('%smodel_%s_.h5' % (checkpoint_dir, model_name),\n",
    "                                                               monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                                               save_weights_only=False, mode='auto')\n",
    "            lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0,\n",
    "                                                            mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train_normalized, batch_size=batch_size, epochs=n_epochs,\n",
    "                      verbose=2, validation_split=1 / num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "\n",
    "        self.model = model\n",
    "        self.tau = tau\n",
    "        self.running_time = time.time() - start_time\n",
    "\n",
    "        # We are done!\n",
    "\n",
    "    def load(self, checkpoint_dir, model_name, loss, compiles):\n",
    "        if not compiles:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name), compile=compiles)\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "        else:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name))\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, X_test, X_test_ctx=None, context=True):\n",
    "        X_test = np.array(X_test, ndmin=3)\n",
    "\n",
    "        model = self.model\n",
    "\n",
    "        T = 10\n",
    "        #if context==True:\n",
    "        X_test_ctx = np.array(X_test_ctx, ndmin=2)\n",
    "        Yt_hat = np.array([model.predict([X_test, X_test_ctx], batch_size=1, verbose=0) for _ in range(T)])\n",
    "        # if context == True:\n",
    "        #     X_test_ctx = np.array(X_test_ctx, ndmin=2)\n",
    "        #     Yt_hat = np.array([model.predict([X_test, X_test_ctx], batch_size=1, verbose=0) for _ in range(T)])\n",
    "        # else:\n",
    "        #     Yt_hat = np.array([model.predict(X_test, batch_size=1, verbose=0) for _ in range(T)])\n",
    "        # Yt_hat = Yt_hat * self.std_y_train + self.mean_y_train\n",
    "        regression = False\n",
    "        if regression:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = np.std(Yt_hat, 0)\n",
    "        else:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = list()\n",
    "            for i in range(Yt_hat.shape[2]):\n",
    "                MC_uncertainty.append(np.std(Yt_hat[:, :, i].squeeze(), 0))\n",
    "\n",
    "        return MC_pred, MC_uncertainty\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9e0e0-d2ba-424e-a9c0-b66974fece77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf446ea6-df71-46bb-9361-222e5f73adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "class GRUModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, X_train_ctx, y_train, regression, loss, n_epochs=100,\n",
    "              normalize=False, y_normalize=False, tau=1.0, dropout=0.05, batch_size=128,\n",
    "              context=True, num_folds=10, model_name='predictor', checkpoint_dir='./checkpoints/'):\n",
    "\n",
    "        if y_normalize:\n",
    "            self.mean_y_train = np.mean(y_train)\n",
    "            self.std_y_train = np.std(y_train)\n",
    "\n",
    "            y_train_normalized = (y_train - self.mean_y_train) / self.std_y_train\n",
    "            y_train_normalized = np.array(y_train_normalized, ndmin=2).T\n",
    "        else:\n",
    "            if len(y_train.shape) == 1:\n",
    "                y_train_normalized = np.array(y_train, ndmin=2).T\n",
    "            else:\n",
    "                y_train_normalized = y_train\n",
    "\n",
    "        # We construct the network\n",
    "        N = X_train.shape[0]\n",
    "        batch_size = batch_size\n",
    "        num_folds = num_folds\n",
    "\n",
    "        inputs = Input(shape=(X_train.shape[1], X_train.shape[2]), name='main_input')\n",
    "        inter = Dropout(dropout)(inputs, training=True)\n",
    "        inter = GRU(30, dropout=dropout, recurrent_dropout=dropout, return_sequences=True)(inter, training=True)\n",
    "        inter = GRU(30, dropout=dropout, recurrent_dropout=dropout)(inter, training=True)\n",
    "        inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "        if context == True:\n",
    "            context_shape = X_train_ctx.shape\n",
    "            auxiliary_input = Input(shape=(context_shape[1],), name='aux_input')\n",
    "            aux_inter = Dropout(dropout)(auxiliary_input, training=True)\n",
    "\n",
    "            inter = keras.layers.concatenate([inter, aux_inter])\n",
    "            inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1], )(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=[inputs, auxiliary_input], outputs=outputs)\n",
    "\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                '%smodel_%s_.h5' % (checkpoint_dir, model_name), monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                save_weights_only=False, mode='auto')\n",
    "            lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0,\n",
    "                                                           mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit([X_train, X_train_ctx], y_train_normalized, batch_size=batch_size, epochs=n_epochs, verbose=2,\n",
    "                      validation_split=1 / num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "        else:\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1], )(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                '%smodel_%s_.h5' % (checkpoint_dir, model_name), monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                save_weights_only=False, mode='auto')\n",
    "            lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0,\n",
    "                                                           mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train_normalized, batch_size=batch_size, epochs=n_epochs, verbose=2,\n",
    "                      validation_split=1 / num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "\n",
    "        self.model = model\n",
    "        self.tau = tau\n",
    "        self.running_time = time.time() - start_time\n",
    "\n",
    "        # We are done!\n",
    "\n",
    "    def load(self, checkpoint_dir, model_name, loss, compiles):\n",
    "        if not compiles:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name), compile=compiles)\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "        else:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name))\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, X_test, X_test_ctx=None, context=True):\n",
    "        X_test = np.array(X_test, ndmin=3)\n",
    "\n",
    "        model = self.model\n",
    "\n",
    "        T = 10\n",
    "        # if context==True:\n",
    "        X_test_ctx = np.array(X_test_ctx, ndmin=2)\n",
    "        Yt_hat = np.array([model.predict([X_test, X_test_ctx], batch_size=1, verbose=0) for _ in range(T)])\n",
    "        # else:\n",
    "        #    Yt_hat = np.array([model.predict(X_test, batch_size=1, verbose=0) for _ in range(T)])\n",
    "        # Yt_hat = Yt_hat * self.std_y_train + self.mean_y_train\n",
    "        regression = False\n",
    "        if regression:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = np.std(Yt_hat, 0)\n",
    "        else:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = list()\n",
    "            for i in range(Yt_hat.shape[2]):\n",
    "                MC_uncertainty.append(np.std(Yt_hat[:, :, i].squeeze(), 0))\n",
    "        return MC_pred, MC_uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673097b6-f680-4ca3-8f9d-c81aa2f4750b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7016e54-53ea-4590-a021-2c7f9314316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "class CNNModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, X_train_ctx, y_train, regression, loss, n_epochs=100,\n",
    "              normalize=False, y_normalize=False, tau=1.0, dropout=0.05, batch_size=128,\n",
    "              context=True, num_folds=10, model_name='predictor', checkpoint_dir='./checkpoints/'):\n",
    "\n",
    "        if y_normalize:\n",
    "            self.mean_y_train = np.mean(y_train)\n",
    "            self.std_y_train = np.std(y_train)\n",
    "\n",
    "            y_train_normalized = (y_train - self.mean_y_train) / self.std_y_train\n",
    "            y_train_normalized = np.array(y_train_normalized, ndmin=2).T\n",
    "        else:\n",
    "            if len(y_train.shape) == 1:\n",
    "                y_train_normalized = np.array(y_train, ndmin=2).T\n",
    "            else:\n",
    "                y_train_normalized = y_train\n",
    "\n",
    "        # We construct the network\n",
    "        N = X_train.shape[0]\n",
    "        batch_size = batch_size\n",
    "        num_folds = num_folds\n",
    "\n",
    "        inputs = Input(shape=(X_train.shape[1], X_train.shape[2]), name='main_input')\n",
    "        inter = Dropout(dropout)(inputs, training=True)\n",
    "        inter = Conv1D(30, kernel_size=3, activation='relu')(inter)\n",
    "        inter = MaxPooling1D(pool_size=2)(inter)\n",
    "        inter = Conv1D(30, kernel_size=3, activation='relu')(inter)\n",
    "        inter = MaxPooling1D(pool_size=2)(inter)\n",
    "        inter = Flatten()(inter)\n",
    "        inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "        if context == True:\n",
    "            context_shape = X_train_ctx.shape\n",
    "            auxiliary_input = Input(shape=(context_shape[1],), name='aux_input')\n",
    "            aux_inter = Dropout(dropout)(auxiliary_input, training=True)\n",
    "\n",
    "            inter = keras.layers.concatenate([inter, aux_inter])\n",
    "            inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1], )(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=[inputs, auxiliary_input], outputs=outputs)\n",
    "\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "            model.compile(loss=loss, optimizer=optimizer)\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                '%smodel_%s_.h5' % (checkpoint_dir, model_name), monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                save_weights_only=False, mode='auto')\n",
    "            lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0,\n",
    "                                                           mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit([X_train, X_train_ctx], y_train_normalized, batch_size=batch_size, epochs=n_epochs, verbose=2,\n",
    "                      validation_split=1 / num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "        else:\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1], )(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "            model.compile(loss=loss, optimizer=optimizer)\n",
    "            \n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                '%smodel_%s_.h5' % (checkpoint_dir, model_name), monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                save_weights_only=False, mode='auto')\n",
    "            lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0,\n",
    "                                                           mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.01)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train_normalized, batch_size=batch_size, epochs=n_epochs, verbose=2,\n",
    "                      validation_split=1 / num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "\n",
    "        self.model = model\n",
    "        self.tau = tau\n",
    "        self.running_time = time.time() - start_time\n",
    "\n",
    "        # We are done!\n",
    "\n",
    "    def load(self, checkpoint_dir, model_name, loss, compiles):\n",
    "        if not compiles:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name), compile=compiles)\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "            model.compile(loss=loss, optimizer=optimizer)\n",
    "        else:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name))\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, X_test, X_test_ctx=None, context=True):\n",
    "        X_test = np.array(X_test, ndmin=3)\n",
    "\n",
    "        model = self.model\n",
    "\n",
    "        T = 10\n",
    "        # if context==True:\n",
    "        X_test_ctx = np.array(X_test_ctx, ndmin=2)\n",
    "        Yt_hat = np.array([model.predict([X_test, X_test_ctx], batch_size=1, verbose=0) for _ in range(T)])\n",
    "        # else:\n",
    "        #    Yt_hat = np.array([model.predict(X_test, batch_size=1, verbose=0) for _ in range(T)])\n",
    "        # Yt_hat = Yt_hat * self.std_y_train + self.mean_y_train\n",
    "        regression = False\n",
    "        if regression:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = np.std(Yt_hat, 0)\n",
    "        else:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = list()\n",
    "            for i in range(Yt_hat.shape[2]):\n",
    "                MC_uncertainty.append(np.std(Yt_hat[:, :, i].squeeze(), 0))\n",
    "        return MC_pred, MC_uncertainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560e98b-f2fb-4296-9c3f-a28b3207fb3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transformer based model\n",
    "\n",
    "We name the model \"TransformerModel\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d29435-5bbf-4531-9d39-40ce67bf2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Transformer(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"rate\": self.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Register the custom Transformer layer\n",
    "get_custom_objects().update({\"Transformer\": Transformer})\n",
    "\n",
    "class TransformerModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, X_train_ctx, y_train, regression, loss, n_epochs=100,\n",
    "              normalize=False, y_normalize=False, tau=1.0, dropout=0.05, batch_size=128, context=True,\n",
    "              num_folds=10, model_name='predictor', checkpoint_dir='./checkpoints/'):\n",
    "\n",
    "        if y_normalize:\n",
    "            self.mean_y_train = np.mean(y_train)\n",
    "            self.std_y_train = np.std(y_train)\n",
    "\n",
    "            y_train_normalized = (y_train - self.mean_y_train) / self.std_y_train\n",
    "            y_train_normalized = np.array(y_train_normalized, ndmin=2).T\n",
    "        else:\n",
    "            if len(y_train.shape) == 1:\n",
    "                y_train_normalized = np.array(y_train, ndmin=2).T\n",
    "            else:\n",
    "                y_train_normalized = y_train\n",
    "\n",
    "        # We construct the network\n",
    "        N = X_train.shape[0]\n",
    "        batch_size = batch_size\n",
    "        num_folds = num_folds\n",
    "\n",
    "        inputs = Input(shape=(X_train.shape[1], X_train.shape[2]), name='main_input')\n",
    "        inter = Dropout(dropout)(inputs, training=True)\n",
    "        inter = Transformer(embed_dim=X_train.shape[2], num_heads=6, ff_dim=64, rate=dropout)(inter, training=True)\n",
    "        inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "        if context:\n",
    "            context_shape = X_train_ctx.shape\n",
    "            auxiliary_input = Input(shape=(context_shape[1],), name='aux_input')\n",
    "            aux_inter = Dropout(dropout)(auxiliary_input, training=True)\n",
    "            aux_inter = tf.expand_dims(aux_inter, axis=1)\n",
    "            aux_inter = tf.tile(aux_inter, [1, X_train.shape[1], 1])  # Reshape to match sequence length\n",
    "            inter = tf.concat([inter, aux_inter], axis=-1)\n",
    "            inter = Dropout(dropout)(inter, training=True)\n",
    "\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1])(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=[inputs, auxiliary_input], outputs=outputs)\n",
    "\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = ModelCheckpoint('%smodel_%s_.h5' % (checkpoint_dir, model_name),\n",
    "                                               monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                               save_weights_only=False, mode='auto')\n",
    "            lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0,\n",
    "                                            mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit([X_train, X_train_ctx], y_train_normalized, batch_size=batch_size, epochs=n_epochs,\n",
    "                      verbose=2, validation_split=1 / num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "        else:\n",
    "            if regression:\n",
    "                outputs = Dense(y_train_normalized.shape[1])(inter)\n",
    "            else:\n",
    "                outputs = Dense(y_train_normalized.shape[1], activation='softmax')(inter)\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model_checkpoint = ModelCheckpoint('%smodel_%s_.h5' % (checkpoint_dir, model_name),\n",
    "                                               monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                               save_weights_only=False, mode='auto')\n",
    "            lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0,\n",
    "                                            mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "            # We iterate the learning process\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train_normalized, batch_size=batch_size, epochs=n_epochs,\n",
    "                      verbose=2, validation_split=1 / num_folds, callbacks=[early_stopping, model_checkpoint, lr_reducer])\n",
    "\n",
    "        self.model = model\n",
    "        self.tau = tau\n",
    "        self.running_time = time.time() - start_time\n",
    "\n",
    "    def load(self, checkpoint_dir, model_name, loss, compiles):\n",
    "        if not compiles:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name), compile=compiles)\n",
    "            model.compile(loss=loss, optimizer='adam')\n",
    "        else:\n",
    "            model = load_model('%smodel_%s_.h5' % (checkpoint_dir, model_name))\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def predict(self, X_test, X_test_ctx=None, context=True):\n",
    "        X_test = np.array(X_test, ndmin=3)\n",
    "\n",
    "        model = self.model\n",
    "\n",
    "        T = 10\n",
    "#        if context == True:\n",
    "        X_test_ctx = np.array(X_test_ctx, ndmin=2)\n",
    "        Yt_hat = np.array([model.predict([X_test, X_test_ctx], batch_size=1, verbose=0) for _ in range(T)])\n",
    "#        else:\n",
    "#            Yt_hat = np.array([model.predict(X_test, batch_size=1, verbose=0) for _ in range(T)])\n",
    "\n",
    "        regression = False\n",
    "        if regression:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = np.std(Yt_hat, 0)\n",
    "        else:\n",
    "            MC_pred = np.mean(Yt_hat, 0)\n",
    "            MC_uncertainty = list()\n",
    "            for i in range(Yt_hat.shape[2]):\n",
    "                MC_uncertainty.append(np.std(Yt_hat[:, :, i].squeeze(), 0))\n",
    "\n",
    "        return MC_pred, MC_uncertainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbccb6b-208f-49c1-818d-4fca3c428ed1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train Model on data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ebbcf-30d7-47c4-807a-0458e997b66c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install and load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca29982-8823-4e11-b231-40bf9b2ad45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_generator import FeatureGenerator\n",
    "\n",
    "import keras\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53e934-a28c-414a-8d8d-4ed2dfe9f5d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define variables (parameters) for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18fc2a-5e56-44c3-8919-e102e0d3c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_values = list()\n",
    "accuracy_sum = 0.0\n",
    "accuracy_value = 0.0\n",
    "precision_values = list()\n",
    "precision_sum = 0.0\n",
    "precision_value = 0.0\n",
    "recall_values = list()\n",
    "recall_sum = 0.0\n",
    "recall_value = 0.0\n",
    "f1_values = list()\n",
    "f1_sum = 0.0\n",
    "f1_value = 0.0\n",
    "training_time_seconds = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396efd6-aba9-4cae-96e1-87af9b999add",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"next_timestamp\"\n",
    "contextual_info= True\n",
    "inter_case_level='Level1'\n",
    "\n",
    "# dnn\n",
    "num_epochs=20\n",
    "learning_rate=0.002\n",
    "num_folds=10\n",
    "batch_size_train=256\n",
    "batch_size_test=1\n",
    "\n",
    "# data\n",
    "data_set = \"modi_BPI_2012_dropna_filter_act.csv\"\n",
    "data_dir = \"../sample_data/real/\"\n",
    "checkpoint_dir = \"./estimation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f344d5-1b35-43fa-b48e-2dfb62fe0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = inter_case_level\n",
    "\n",
    "filename = data_dir + data_set\n",
    "model_name = data_set + task + '_gru'\n",
    "\n",
    "contextual_info = contextual_info\n",
    "if task == 'next_activity':\n",
    "    loss = 'categorical_crossentropy'\n",
    "    regression = False\n",
    "elif task == 'next_timestamp':\n",
    "    loss = 'mae'\n",
    "    regression = True\n",
    "\n",
    "batch_size = batch_size_train\n",
    "num_folds = num_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb51331-7243-4e44-8954-9a3329b28a2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3e5a0-bcfa-45e5-b349-64db952bb20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load data\n",
    "FG = FeatureGenerator()\n",
    "df = FG.create_initial_log(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052fdd8-e9a1-48bd-8323-b6bb832e0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test\n",
    "#train_df, test_df = FG.train_test_split(df, 0.7, 0.3)\n",
    "train_df = df\n",
    "test_df = train_df\n",
    "#create train\n",
    "train_df = FG.order_csv_time(train_df)\n",
    "train_df = FG.queue_level(train_df)\n",
    "train_df.to_csv('./training_data.csv')\n",
    "state_list = FG.get_states(train_df)\n",
    "train_X, train_Y_Event, train_Y_Time = FG.one_hot_encode_history(train_df, checkpoint_dir+data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aad73f-9acf-4b47-9a7e-bc6de63bee15",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a509a2-fe98-4be0-adf5-644d7d1230d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if contextual_info:\n",
    "    train_context_X = FG.generate_context_feature(train_df,state_list)\n",
    "    model = GRUModel()\n",
    "    if regression:\n",
    "        model.train(train_X, train_context_X, train_Y_Time, regression, loss, batch_size=batch_size, num_folds=num_folds, model_name=model_name, checkpoint_dir=checkpoint_dir)\n",
    "    else:\n",
    "        model.train(train_X, train_context_X, train_Y_Event, regression, loss, batch_size=batch_size, num_folds=num_folds, model_name=model_name, checkpoint_dir=checkpoint_dir)\n",
    "else:\n",
    "    model_name += '_no_context_'\n",
    "    train_context_X = None\n",
    "    model = GRUModel()\n",
    "    if regression:\n",
    "        model.train(train_X, train_context_X, train_Y_Time, regression, loss, batch_size=batch_size, num_folds=num_folds, model_name=model_name, checkpoint_dir=checkpoint_dir, context=contextual_info)\n",
    "    else:\n",
    "        model.train(train_X, train_context_X, train_Y_Event, regression, loss, batch_size=batch_size, num_folds=num_folds, model_name=model_name, checkpoint_dir=checkpoint_dir, context=contextual_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f0c9a-5144-44fb-9e29-ebb647a428e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y_Event, test_Y_Time = train_X, train_Y_Event, train_Y_Time\n",
    "test_context_X = train_context_X\n",
    "test_X = test_X[500]\n",
    "test_context_X = test_context_X[500]\n",
    "test_Y_Event = test_Y_Event[500]\n",
    "MC_pred, MC_uncertainty = model.predict(test_X, test_context_X, test_Y_Event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5f7a6-1749-4bfd-82d9-55c7f636b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_pred, MC_uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeda471-1437-4253-9b66-5f130f2f0246",
   "metadata": {},
   "source": [
    "### Plotting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b777779-6d1d-4c97-8570-bd52c51c7357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GRUModel()\n",
    "loss = 'categorical_crossentropy'\n",
    "compiles = False\n",
    "model.load('./checkpoints/', 'modi_BPI_2012_dropna_filter_act.csvnext_activity_gru', loss, compiles)\n",
    "\n",
    "tf.keras.utils.plot_model(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7d645f2-340b-491b-b872-80c4a49a3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 20, 55)]     0           []                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 20, 55)       0           ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 20, 30)       7830        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 30)           5580        ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 30)           0           ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 6)            0           ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 36)           0           ['dropout_1[0][0]',              \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 36)           0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 7)            259         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,669\n",
      "Trainable params: 13,669\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9af7a8-7d1c-44d4-bbf0-22e29493a0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
