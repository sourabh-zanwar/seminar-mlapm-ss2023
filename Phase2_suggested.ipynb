{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c066a07a-715b-459f-bf8f-578aa04e09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import shutil\n",
    "from PyProM.src.data.Eventlog import Eventlog\n",
    "from object.object import Instance, Resource\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "\n",
    "from prediction.model import UniLSTM, BiLSTM, TransformerModel, Transformer, CNNModel, GRUModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4645473-266f-4a8c-a428-7bfe7d9f3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0bbb280-8cc6-464c-9494-5cbd6308578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_custom_objects().update({\"Transformer\": Transformer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8c1c3a-c02f-40bd-bf04-c0ff4dfd3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(f):\n",
    "    def wrap(*args):\n",
    "        time1 = time.time()\n",
    "        ret = f(*args)\n",
    "        time2 = time.time()\n",
    "        #print('{:s} function took {:.3f} ms'.format(f.__name__, (time2-time1)*1000.0))\n",
    "\n",
    "        return ret\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2ca261-4eb9-4f13-940d-0f2d589a9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuggestedOptimizer(object):\n",
    "\tdef __init__(self, *args, **kwargs):\n",
    "\t\tsuper(SuggestedOptimizer, self).__init__(*args, **kwargs)\n",
    "\t\tself.w_comp_time = list()\n",
    "\t\tself.pred_time = list()\n",
    "\t\tself.act_res_mat = None\n",
    "\n",
    "\tdef read_act_res_mat(self, path=\"./sample_data/new_resource_0806_1.csv\"):\n",
    "\t\t\"\"\"Read activity-resource matrix which specifies the processing time\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tpath -- file path\n",
    "\t\t\"\"\"\n",
    "\t\tact_res_mat = pd.read_csv(path)\n",
    "\t\tact_res_mat['Resource'] = 'Resource'+act_res_mat['Resource'].astype('str')\n",
    "\t\tact_res_mat = act_res_mat.set_index('Resource')\n",
    "\t\tact_res_mat = act_res_mat.to_dict()\n",
    "\t\treturn act_res_mat\n",
    "\n",
    "\n",
    "\tdef load_data(self,path):\n",
    "\t\t\"\"\"Load eventlog\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tpath -- file path\n",
    "\t\t\"\"\"\n",
    "\t\teventlog = Eventlog.from_txt(path, sep=',')\n",
    "\t\teventlog = eventlog.assign_caseid('CASE_ID')\n",
    "\t\teventlog = eventlog.assign_activity('Activity')\n",
    "\t\teventlog = eventlog.assign_resource('Resource')\n",
    "\t\tself.activities = list(set(eventlog['Activity']))\n",
    "\t\treturn eventlog\n",
    "\n",
    "\tdef load_real_data(self,path):\n",
    "\t\t\"\"\"Load real-life log (Requires modification according to the schema)\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tpath -- file path\n",
    "\t\t\"\"\"\n",
    "\t\teventlog = Eventlog.from_txt(path, sep=',')\n",
    "\t\teventlog = eventlog.assign_caseid('CASE_ID')\n",
    "\t\teventlog = eventlog.assign_activity('Activity')\n",
    "\t\teventlog['Resource'] = eventlog['Resource'].astype(int)\n",
    "\t\teventlog = eventlog.assign_resource('Resource')\n",
    "\t\teventlog = eventlog.assign_timestamp(name='StartTimestamp', new_name='StartTimestamp', _format = '%Y.%m.%d %H:%M:%S', errors='raise')\n",
    "\n",
    "\t\tdef to_minute(x):\n",
    "\t\t\tt = x.time()\n",
    "\t\t\tminutes = t.hour * 60 + t.minute\n",
    "\t\t\treturn minutes\n",
    "\n",
    "\t\teventlog['Start'] = eventlog['StartTimestamp'].apply(to_minute)\n",
    "\t\treturn eventlog\n",
    "\n",
    "\tdef initialize_test_instance(self, eventlog):\n",
    "\t\t\"\"\"Initialize test instance\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\teventlog -- test log\n",
    "\t\t\"\"\"\n",
    "\t\tinstance_set = list()\n",
    "\t\tactivity_trace = eventlog.get_event_trace(workers=4, value='Activity')\n",
    "\t\tresource_trace = eventlog.get_event_trace(4,'Resource')\n",
    "\t\ttime_trace = eventlog.get_event_trace(workers=4, value='Start')\n",
    "\t\tdur_trace = eventlog.get_event_trace(workers=4, value='Duration')\n",
    "\t\tweight_trace = eventlog.get_event_trace(workers=4, value='weight')\n",
    "\n",
    "\t\tfor case in activity_trace:\n",
    "\t\t\trelease_time = min(time_trace[case])\n",
    "\t\t\tweight = min(weight_trace[case])\n",
    "\t\t\tinstance = Instance(name=case, weight=weight, release_time=release_time, act_sequence=activity_trace[case], res_sequence=resource_trace[case],dur_sequence=dur_trace[case])\n",
    "\t\t\tinstance_set.append(instance)\n",
    "\t\treturn instance_set\n",
    "\n",
    "\tdef initialize_real_instance(self, eventlog):\n",
    "\t\t\"\"\"Initialize real instance\n",
    "\t\tDifference between test and real instance\n",
    "\t\t1. Real - using date info.\n",
    "\t\t2. Real - release time is set to the appearing time of an instance\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\teventlog -- test log\n",
    "\t\t\"\"\"\n",
    "\t\tinstance_set = list()\n",
    "\t\tactivity_trace = eventlog.get_event_trace(workers=4, value='Activity')\n",
    "\t\tresource_trace = eventlog.get_event_trace(4,'Resource')\n",
    "\t\tdate_trace = eventlog.get_event_trace(workers=4, value='StartDate')\n",
    "\t\ttime_trace = eventlog.get_event_trace(workers=4, value='Start')\n",
    "\t\tdur_trace = eventlog.get_event_trace(workers=4, value='Duration')\n",
    "\t\tweight_trace = eventlog.get_event_trace(workers=4, value='weight')\n",
    "\n",
    "\t\tfor case in date_trace:\n",
    "\t\t\tfor j, time in enumerate(date_trace[case]):\n",
    "\t\t\t\tif time == self.date:\n",
    "\t\t\t\t\tinitial_index =j-1\n",
    "\t\t\t\t\trelease_time = time_trace[case][j]\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tweight = min(weight_trace[case])\n",
    "\t\t\tinstance = Instance(name=case, weight=weight, release_time=release_time, act_sequence=activity_trace[case], res_sequence=resource_trace[case],dur_sequence=dur_trace[case], initial_index=initial_index)\n",
    "\t\t\tinstance_set.append(instance)\n",
    "\n",
    "\t\treturn instance_set\n",
    "\n",
    "\tdef initialize_test_resource(self, eventlog):\n",
    "\t\t\"\"\"Initialize test resource\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\teventlog -- test log\n",
    "\t\t\"\"\"\n",
    "\t\tresource_set = list()\n",
    "\t\tresource_list = sorted(list(eventlog.get_resources()))\n",
    "\t\tfor res in resource_list:\n",
    "\t\t\tact_list = list(eventlog.loc[eventlog['Resource']==res,'Activity'].unique())\n",
    "\t\t\tresource = Resource(res, act_list)\n",
    "\t\t\tresource_set.append(resource)\n",
    "\t\treturn resource_set\n",
    "\n",
    "\tdef initialize_real_resource(self, test_log):\n",
    "\t\t\"\"\"Initialize real instance\n",
    "\t\tNo difference at the moment\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\ttest_log -- test log\n",
    "\t\t\"\"\"\n",
    "\t\tresource_set = list()\n",
    "\t\tresource_list = sorted(list(test_log.get_resources()))\n",
    "\t\tfor res in resource_list:\n",
    "\t\t\tact_list = list(test_log.loc[test_log['Resource']==res,'Activity'].unique())\n",
    "\t\t\tresource = Resource(res, act_list)\n",
    "\t\t\tresource_set.append(resource)\n",
    "\t\treturn resource_set\n",
    "\n",
    "\tdef set_basic_info(self, eventlog):\n",
    "\t\t\"\"\"set basic info. for instances\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\teventlog -- test log\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# To be aligned with the entire log, we load the information generated from entire log\n",
    "\t\tif self.mode == 'test':\n",
    "\t\t\twith open('./prediction/checkpoints/traininglog_0806_1.csv_activities.pkl', 'rb') as f:\n",
    "\t\t\t\tactivities = pickle.load(f)\n",
    "\t\t\twith open('./prediction/checkpoints/traininglog_0806_1.csv_resources.pkl', 'rb') as f:\n",
    "\t\t\t\tresources = pickle.load(f)\n",
    "\t\telse:\n",
    "\t\t\twith open('./prediction/checkpoints/modi_BPI_2012_dropna_filter_act.csv_activities.pkl', 'rb') as f:\n",
    "\t\t\t\tactivities = pickle.load(f)\n",
    "\t\t\twith open('./prediction/checkpoints/modi_BPI_2012_dropna_filter_act.csv_resources.pkl', 'rb') as f:\n",
    "\t\t\t\tresources = pickle.load(f)\n",
    "\t\tact_char_to_int = dict((str(c), i) for i, c in enumerate(activities))\n",
    "\t\tact_int_to_char = dict((i, str(c)) for i, c in enumerate(activities))\n",
    "\t\tres_char_to_int = dict((str(c), i) for i, c in enumerate(resources))\n",
    "\t\tres_int_to_char = dict((i, str(c)) for i, c in enumerate(resources))\n",
    "\n",
    "\t\t# for contextual information\n",
    "\t\tself.queue = OrderedDict()\n",
    "\t\tfor act in activities:\n",
    "\t\t\tif act != '!':\n",
    "\t\t\t\tself.queue[act] = 0\n",
    "\n",
    "\t\t# maxlen information\n",
    "\t\tactivity_trace = eventlog.get_event_trace(4,'Activity')\n",
    "\t\ttrace_len = [len(x) for x in activity_trace.values()]\n",
    "\t\tmaxlen = max(trace_len)\n",
    "\n",
    "\t\t# set info.\n",
    "\t\tInstance.set_activity_list(activities)\n",
    "\t\tInstance.set_resource_list(resources)\n",
    "\t\tInstance.set_act_char_to_int(act_char_to_int)\n",
    "\t\tInstance.set_act_int_to_char(act_int_to_char)\n",
    "\t\tInstance.set_res_char_to_int(res_char_to_int)\n",
    "\t\tInstance.set_res_int_to_char(res_int_to_char)\n",
    "\t\tInstance.set_maxlen(maxlen)\n",
    "\n",
    "\tdef load_model(self, checkpoint_dir, model_name, loss):\n",
    "\t\t\"\"\"load prediction model\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tcheckpoint_dir -- directory path\n",
    "\t\tmodel_name -- decide which model to load\n",
    "\t\t\"\"\"\n",
    "\t\tmodel = GRUModel()\n",
    "\t\tmodel.load(checkpoint_dir, model_name, loss, compiles=False)\n",
    "\t\treturn model\n",
    "\n",
    "\tdef prepare_test(self, test_path, res_info_path):\n",
    "\t\t\"\"\"prepare experiment on the artificial log\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\ttest_path -- path to the test log\n",
    "\t\tres_info_path -- path to the activity-resource processing time\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tcheckpoint_dir = './prediction/checkpoints/'\n",
    "\t\tmodelname_next_act = 'traininglog_0806_1.csv' + 'next_activity'\n",
    "\t\tmodelname_next_time = 'traininglog_0806_1.csv' + 'next_timestamp'\n",
    "\n",
    "\t\t# load prediction model\n",
    "\t\tmodel_next_act = self.load_model(checkpoint_dir, modelname_next_act)\n",
    "\t\tmodel_next_time = self.load_model(checkpoint_dir, modelname_next_time)\n",
    "\n",
    "\t\t# set prediction model\n",
    "\t\tInstance.set_model_next_act(model_next_act)\n",
    "\t\tInstance.set_model_next_time(model_next_time)\n",
    "\n",
    "\t\t# load log\n",
    "\t\ttest_log = self.load_data(path=test_path)\n",
    "\n",
    "\t\t#initialize resource set\n",
    "\t\tresource_set = self.initialize_test_resource(test_log)\n",
    "\n",
    "\t\t#create act-res matrix\n",
    "\t\tself.act_res_mat = self.read_act_res_mat(res_info_path)\n",
    "\n",
    "\t\t# initialize instance set\n",
    "\t\tinstance_set = self.initialize_test_instance(test_log)\n",
    "\n",
    "\t\t#Set attributes of instance -> to be used to gernerate input for prediction\n",
    "\t\tself.set_basic_info(test_log)\n",
    "\n",
    "\t\treturn resource_set, instance_set\n",
    "\n",
    "\tdef prepare_real(self, test_path, org_log_path):\n",
    "\t\t\"\"\"prepare experiment on the real log\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\ttest_path -- path to the test log\n",
    "\t\torg_log_path -- path to the entire log\n",
    "\t\t\"\"\"\n",
    "\t\tcheckpoint_dir = './prediction/checkpoints/'\n",
    "\t\tmodelname_next_act = 'modi_BPI_2012_dropna_filter_act.csv' + 'next_activity_gru'\n",
    "\t\tmodelname_next_time = 'modi_BPI_2012_dropna_filter_act.csv' + 'next_timestamp_gru'\n",
    "\n",
    "\t\t# load prediction model\n",
    "\t\tmodel_next_act = self.load_model(checkpoint_dir, modelname_next_act, loss = 'categorical_crossentropy')\n",
    "\t\tmodel_next_time = self.load_model(checkpoint_dir, modelname_next_time, loss = 'mae')\n",
    "\n",
    "\t\t# set prediction model\n",
    "\t\tInstance.set_model_next_act(model_next_act)\n",
    "\t\tInstance.set_model_next_time(model_next_time)\n",
    "\n",
    "\t\t# (CHANGED)\n",
    "\t\test_dir = './prediction/estimation/'\n",
    "\t\testname_next_time = 'modi_BPI_2012_dropna_filter_act.csv' + 'next_timestamp_gru'\n",
    "\t\t# load estimation model\n",
    "\t\test_next_time = self.load_model(est_dir, estname_next_time,loss = 'mae')\n",
    "\n",
    "\t\t# set prediction model\n",
    "\t\tInstance.set_est_next_time(est_next_time)\n",
    "\n",
    "\t\t# load eventlog\n",
    "\t\teventlog = self.load_real_data(path=org_log_path)\n",
    "\n",
    "\t\t# load test log\n",
    "\t\ttest_log = self.load_real_data(path=test_path)\n",
    "\n",
    "\t\t#no act-res matrix\n",
    "\t\tself.act_res_mat = None\n",
    "\n",
    "\t\t# initialize instance set\n",
    "\t\tinstance_set = self.initialize_real_instance(test_log)\n",
    "\n",
    "\t\t#initialize resource set\n",
    "\t\tresource_set = self.initialize_real_resource(test_log)\n",
    "\n",
    "\t\t#Set attributes of instance -> to be used to gernerate input for prediction\n",
    "\t\tself.set_basic_info(eventlog)\n",
    "\n",
    "\t\treturn resource_set, instance_set\n",
    "\n",
    "\t#@timing\n",
    "\tdef update_ongoing_instances(self, instance_set, ongoing_instance, t):\n",
    "\t\t\"\"\"include released instances to the ongoing instance set\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tinstance_set -- all instances for resource allocation\n",
    "\t\tongoing_instance -- ongoing instance set\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in instance_set:\n",
    "\t\t\tif i.get_release_time() == t:\n",
    "\t\t\t\tongoing_instance.append(i)\n",
    "\t\treturn ongoing_instance\n",
    "\n",
    "\t#@timing\n",
    "\tdef update_object(self, ongoing_instance, resource_set, t):\n",
    "\t\t\"\"\"create the bipartite graph with the prediction results\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tongoing_instance -- ongoing instance set\n",
    "\t\tresource_set -- all resources for resource allocation\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\tG = nx.DiGraph()\n",
    "\t\t# if resource is free, set the status to 'True'\n",
    "\t\tfor j in resource_set:\n",
    "\t\t\tif j.get_next_actual_ts() <= t:\n",
    "\t\t\t\tj.set_status(True)\n",
    "\n",
    "\t\t# if instance is free, set the status to 'True'\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in ongoing_instance:\n",
    "\t\t\tif i.get_next_actual_ts() <= t:\n",
    "\t\t\t\ti.set_status(True)\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# if resource is free, set the status to 'True'\n",
    "\t\tfor i in ongoing_instance:\n",
    "\t\t\t# if instance finishes current operation,\n",
    "\t\t\tif i.get_next_actual_ts() == t:\n",
    "\t\t\t\t# set the status to 'True'\n",
    "\t\t\t\ti.set_status(True)\n",
    "\n",
    "\t\t\t\t# update contextual information\n",
    "\t\t\t\tcur_actual_act = i.get_cur_actual_act()\n",
    "\t\t\t\tif cur_actual_act != False:\n",
    "\t\t\t\t\tself.queue[cur_actual_act] -= 1\n",
    "\n",
    "\t\t\t\tif self.exp_name != 'exp_2':\n",
    "\t\t\t\t\t# if it has just been released or the next act. prediction was wrong, update the processing time prediction\n",
    "\t\t\t\t\tif i.first or i.get_next_actual_act() != i.get_next_pred_act():\n",
    "\t\t\t\t\t\ti.clear_pred_act_dur()\n",
    "\t\t\t\t\t\tfor j in resource_set:\n",
    "\t\t\t\t\t\t\tif i.get_next_actual_act() in j.get_skills():\n",
    "\t\t\t\t\t\t\t\tnext_pred_dur, next_time_uncertainty = i.predict_next_time(self.queue, context=True, pred_act=i.get_next_actual_act(), resource=j.get_name())\n",
    "\t\t\t\t\t\t\t\t# set prediction uncertainty to 0 since it is ready for the next act.\n",
    "\t\t\t\t\t\t\t\ti.set_next_act_uncertainty(0)\n",
    "\t\t\t\t\t\t\t\ti.set_pred_act_dur(j, next_pred_dur, 0)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t#set prediction uncertainty to 0 since it is ready for the next act.\n",
    "\t\t\t\t\t\ti.set_next_act_uncertainty(0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# if it has just been released or the next act. prediction was wrong, update the processing time prediction\n",
    "\t\t\t\t\tif i.first or i.get_next_actual_act() != i.get_next_pred_act():\n",
    "\t\t\t\t\t\ti.clear_pred_act_dur()\n",
    "\t\t\t\t\t\tfor j in resource_set:\n",
    "\t\t\t\t\t\t\tif i.get_next_actual_act() in j.get_skills():\n",
    "\t\t\t\t\t\t\t\tnext_pred_dur, next_time_uncertainty = int(self.act_res_mat[i.get_next_actual_act()][j.get_name()]), 0\n",
    "\t\t\t\t\t\t\t\t# give noise\n",
    "\t\t\t\t\t\t\t\tif np.random.uniform(0,1) < 0.5:\n",
    "\t\t\t\t\t\t\t\t\tnext_pred_dur += self.precision * next_pred_dur\n",
    "\t\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\tnext_pred_dur -= self.precision * next_pred_dur\n",
    "\t\t\t\t\t\t\t\tnext_pred_dur = round(next_pred_dur)\n",
    "\t\t\t\t\t\t\t\tif next_pred_dur == 0:\n",
    "\t\t\t\t\t\t\t\t\tnext_pred_dur = 1\n",
    "\n",
    "\t\t\t\t\t\t\t\ti.set_next_act_uncertainty(0)\n",
    "\t\t\t\t\t\t\t\ti.set_pred_act_dur(j, next_pred_dur, 0)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t#set prediction uncertainty to 0 since it is ready for the next act.\n",
    "\t\t\t\t\t\ti.set_next_act_uncertainty(0)\n",
    "\n",
    "\t\t\t# if instance is under operation and the next act. prediction uncertainty is above the threshold, we do not allocate resources for it\n",
    "\t\t\telif i.get_next_actual_ts() > t:\n",
    "\t\t\t\tif i.get_next_act_uncertainty() > self.act_uncertainty:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tfor j in i.get_pred_act_dur_dict().keys():\n",
    "\t\t\t\t# if the processing time prediction uncertainty is above the threshold, we do not include the edge.\n",
    "\t\t\t\tif i.get_next_actual_ts() > t:\n",
    "\t\t\t\t\tif i.get_next_ts_uncertainty(j) > self.ts_uncertainty and j.get_next_ts_uncertainty() > self.ts_uncertainty:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t# generate bipartite graph\n",
    "\t\t\t\tG.add_edge('s',i, capacity=1)\n",
    "\t\t\t\tG.add_edge(j,'t',capacity=1)\n",
    "\t\t\t\tweight = i.get_weight()\n",
    "\t\t\t\tpred_dur = i.get_pred_act_dur(j)\n",
    "\t\t\t\tpred_dur += max([i.get_next_pred_ts()-t, j.get_next_pred_ts()-t, 0])\n",
    "\t\t\t\tcost = int(pred_dur / weight * 10)\n",
    "\t\t\t\tG.add_edge(i,j,weight=cost,capacity=1, pred_dur=pred_dur)\n",
    "\n",
    "\t\treturn G\n",
    "\n",
    "\t#@timing\n",
    "\tdef update_plan(self, G,t):\n",
    "\t\t\"\"\"solve the min-cost max-flow algorithm to find an optimal schedule\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tG -- bipartite graph\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\tnodes=G.nodes()\n",
    "\t\tif len(nodes)!=0:\n",
    "\t\t\tM = nx.max_flow_min_cost(G, 's', 't')\n",
    "\t\telse:\n",
    "\t\t\tM=False\n",
    "\t\t#M = MinCost_MaxFlow(s,t) # dict of dict form\n",
    "\t\treturn M\n",
    "\n",
    "\tdef modify_plan(self, G, M, t):\n",
    "\t\t\"\"\"if some instances can be handled within the waiting time for best-matched instance, handle the instance who has the maximum weight.\n",
    "\t\t(We don't use it at the moment)\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tG -- bipartite graph\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\tif M!=False:\n",
    "\t\t\tfor i, _ in M.items():\n",
    "\t\t\t\tif isinstance(i, Instance)==False:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# if some instances can be handled within the waiting time for best-matched instance, handle the instance who has the maximum weight.\n",
    "\t\t\t\ttemp_dict = dict()\n",
    "\t\t\t\tfor j, val in M[i].items():\n",
    "\t\t\t\t\tif val==1:\n",
    "\t\t\t\t\t\tremaining = i.get_next_actual_ts()-t\n",
    "\t\t\t\t\t\tif remaining <= 0:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\tin_edges_to_j = G.in_edges([j], data=True)\n",
    "\t\t\t\t\t\tfor source, dest, data in in_edges_to_j:\n",
    "\t\t\t\t\t\t\tif source.get_status()==True:\n",
    "\t\t\t\t\t\t\t\tif data['pred_dur'] <= remaining:\n",
    "\t\t\t\t\t\t\t\t\t#Also, we should check whether source is already assigned.\n",
    "\t\t\t\t\t\t\t\t\tassigned = False\n",
    "\t\t\t\t\t\t\t\t\tfor r, val in M[source].items():\n",
    "\t\t\t\t\t\t\t\t\t\tif val == 1:\n",
    "\t\t\t\t\t\t\t\t\t\t\tassigned = True\n",
    "\t\t\t\t\t\t\t\t\tif assigned == False:\n",
    "\t\t\t\t\t\t\t\t\t\ttemp_dict[source] = source.get_weight()\n",
    "\n",
    "\t\t\t\tif len(temp_dict)!=0:\n",
    "\t\t\t\t\tnew_instance = max(temp_dict, key=temp_dict.get)\n",
    "\t\t\t\t\tM[i][j] = 0\n",
    "\t\t\t\t\tM[new_instance][j] = 1\n",
    "\t\t\t\t\t#print(\"Match changed: from {} to {}, {}\".format(i,new_instance, j.get_name()))\n",
    "\t\treturn M\n",
    "\n",
    "\n",
    "\t#@timing\n",
    "\tdef execute_plan(self, ongoing_instance, resource_set, M, t):\n",
    "\t\t\"\"\"execute the resource allocation and update the situation accordingly.\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tongoing_instance -- ongoing instance set\n",
    "\t\tresource_set -- all resources for resource allocation\n",
    "\t\tM -- optimal schedule\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tready_instance = [x for x in ongoing_instance if x.get_status()==True]\n",
    "\t\tready_resource = [x for x in resource_set if x.get_status()==True]\n",
    "\t\tif M!=False:\n",
    "\t\t\tfor i in M:\n",
    "\t\t\t\tif i in ready_instance:\n",
    "\t\t\t\t\tfor j, val in M[i].items():\n",
    "\t\t\t\t\t\t# check if there is a flow\n",
    "\t\t\t\t\t\tif val==1 and M[j]['t']==1:\n",
    "\t\t\t\t\t\t\tif j in ready_resource:\n",
    "\t\t\t\t\t\t\t\t# if both instance and resource are ready for resource allocation,\n",
    "\t\t\t\t\t\t\t\t# update the current situation regarding the instance\n",
    "\t\t\t\t\t\t\t\t# (CHANGED)\n",
    "\t\t\t\t\t\t\t\ti.update_actuals(t, j, self.mode, self.act_res_mat,self.queue)\n",
    "\n",
    "\t\t\t\t\t\t\t\t# update the info. for the resource\n",
    "\t\t\t\t\t\t\t\tj.set_next_pred_ts(i.get_next_pred_ts())\n",
    "\t\t\t\t\t\t\t\tj.set_next_ts_uncertainty(i.get_next_ts_uncertainty(j))\n",
    "\t\t\t\t\t\t\t\tj.set_next_actual_ts(i.get_next_actual_ts())\n",
    "\t\t\t\t\t\t\t\tj.set_status(False)\n",
    "\n",
    "\t\t\t\t\t\t\t\t# update contextual information\n",
    "\t\t\t\t\t\t\t\tcur_actual_act = i.get_cur_actual_act()\n",
    "\t\t\t\t\t\t\t\tif cur_actual_act != False:\n",
    "\t\t\t\t\t\t\t\t\tself.queue[cur_actual_act] += 1\n",
    "\n",
    "\t\t\t\t\t\t\t\tif self.exp_name != 'exp_2':\n",
    "\t\t\t\t\t\t\t\t\tnext_pred_act, next_act_uncertainty = i.predict_next_act(self.queue, context=True)\n",
    "\t\t\t\t\t\t\t\t\ti.set_next_pred_act(next_pred_act)\n",
    "\t\t\t\t\t\t\t\t\ti.set_next_act_uncertainty(next_act_uncertainty)\n",
    "\t\t\t\t\t\t\t\telse:\n",
    "\n",
    "\t\t\t\t\t\t\t\t\tif np.random.uniform(0,1) > self.precision:\n",
    "\t\t\t\t\t\t\t\t\t\tnext_pred_act, next_act_uncertainty = i.get_next_actual_act(), 0\n",
    "\t\t\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\t\tactivities = copy.deepcopy(self.activities)\n",
    "\t\t\t\t\t\t\t\t\t\tactivities.remove(i.get_next_actual_act())\n",
    "\t\t\t\t\t\t\t\t\t\tnext_pred_act, next_act_uncertainty = random.choice(activities), 0\n",
    "\n",
    "\t\t\t\t\t\t\t\t\ti.set_next_pred_act(next_pred_act)\n",
    "\t\t\t\t\t\t\t\t\ti.set_next_act_uncertainty(next_act_uncertainty)\n",
    "\n",
    "\t\t\t\t\t\t\t\t# clear dict for processing time and predict the processing time for the next activity\n",
    "\t\t\t\t\t\t\t\ti.clear_pred_act_dur()\n",
    "\t\t\t\t\t\t\t\tfor k in resource_set:\n",
    "\t\t\t\t\t\t\t\t\tif next_pred_act in k.get_skills():\n",
    "\t\t\t\t\t\t\t\t\t\tif self.exp_name != 'exp_2':\n",
    "\t\t\t\t\t\t\t\t\t\t\tnext_pred_dur, next_time_uncertainty = i.predict_next_time(self.queue, context=True, pred_act=next_pred_act, resource=k.get_name())\n",
    "\t\t\t\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\t\t\t# give noise\n",
    "\t\t\t\t\t\t\t\t\t\t\tnext_pred_dur, next_time_uncertainty = int(self.act_res_mat[next_pred_act][k.get_name()]), 0\n",
    "\t\t\t\t\t\t\t\t\t\t\tif np.random.uniform(0,1) < 0.5:\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnext_pred_dur += self.precision * next_pred_dur\n",
    "\t\t\t\t\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnext_pred_dur -= self.precision * next_pred_dur\n",
    "\t\t\t\t\t\t\t\t\t\t\tnext_pred_dur = round(next_pred_dur)\n",
    "\t\t\t\t\t\t\t\t\t\t\tif next_pred_dur <= 0:\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnext_pred_dur = 1\n",
    "\t\t\t\t\t\t\t\t\t\ti.set_pred_act_dur(k, next_pred_dur, next_time_uncertainty)\n",
    "\n",
    "\n",
    "\t#@timing\n",
    "\tdef update_completes(self, completes, ongoing_instance, t):\n",
    "\t\t\"\"\"check if instance finishes its operation\n",
    "\n",
    "\t\tKeyword arguments:\n",
    "\t\tcompletes -- set of complete instances\n",
    "\t\tongoing_instance -- ongoing instance set\n",
    "\t\tt -- current time\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in ongoing_instance:\n",
    "\t\t\tfinished = i.check_finished(t)\n",
    "\t\t\tif finished==True:\n",
    "\t\t\t\t# update the contextual information\n",
    "\t\t\t\tcur_actual_act = i.get_cur_actual_act()\n",
    "\t\t\t\tself.queue[cur_actual_act] -= 1\n",
    "\n",
    "\t\t\t\t# compute the total weighted completion time and computation time\n",
    "\t\t\t\ti.set_weighted_comp()\n",
    "\t\t\t\tongoing_instance.remove(i)\n",
    "\t\t\t\tcompletes.append(i)\n",
    "\t\t\t\tself.w_comp_time.append(i.get_weighted_comp())\n",
    "\t\t\t\tself.pred_time += i.get_pred_time_list()\n",
    "\t\t\t\t\"\"\"\n",
    "\t\t\t\twith open(\"./exp_result/exp_6.txt\", \"a\") as f:\n",
    "\t\t\t\t\tf.write(\"{}-{}: start at {}, end at {}, weighted_comp = {} \\n\".format(i.get_name(), i.get_weight(), i.release_time, i.get_next_actual_ts(), i.get_weighted_comp()))\n",
    "\t\t\t\t\"\"\"\n",
    "\t\treturn completes\n",
    "\n",
    "\tdef main(self, test_path, mode, alpha, beta, precision, date, exp_name, **kwargs):\n",
    "\t\ttime1 = time.time()\n",
    "\t\tt=0\n",
    "\t\t#initialize\n",
    "\t\tongoing_instance = list()\n",
    "\t\tcompletes = list()\n",
    "\t\tself.exp_name = exp_name\n",
    "\t\tself.act_uncertainty=alpha\n",
    "\t\tself.ts_uncertainty=beta\n",
    "\t\tself.precision = precision\n",
    "\t\tself.mode = mode\n",
    "\t\tself.date = date\n",
    "\n",
    "\t\tif mode=='test':\n",
    "\t\t\tif \"res_info_path\" in kwargs:\n",
    "\t\t\t\tres_info_path = kwargs['res_info_path']\n",
    "\t\t\telse:\n",
    "\t\t\t\traise AttributeError(\"Resource Information is required\")\n",
    "\t\t\tresource_set, instance_set = self.prepare_test(test_path, res_info_path)\n",
    "\n",
    "\t\telif mode == 'real':\n",
    "\t\t\tif 'org_log_path' in kwargs:\n",
    "\t\t\t\torg_log_path = kwargs['org_log_path']\n",
    "\t\t\telse:\n",
    "\t\t\t\traise AttributeError(\"no org_log_path given.\")\n",
    "\t\t\tresource_set, instance_set = self.prepare_real(test_path, org_log_path)\n",
    "\t\t\t#print(\"num resource:{}\".format(len(resource_set)))\n",
    "\n",
    "\t\telse:\n",
    "\t\t\traise AttributeError('Optimization mode should be given.')\n",
    "\n",
    "\t\twhile len(instance_set) != len(completes):\n",
    "\t\t\t#print(\"{} begins\".format(t))\n",
    "\t\t\t#Add ongoing instance\n",
    "\t\t\tongoing_instance = self.update_ongoing_instances(instance_set, ongoing_instance, t)\n",
    "\t\t\t#print('current ongoing instance: {}'.format(len(ongoing_instance)))\n",
    "\n",
    "\t\t\tG = self.update_object(ongoing_instance, resource_set, t)\n",
    "\t\t\t#print(\"{} updated object\".format(t))\n",
    "\n",
    "\t\t\tM = self.update_plan(G,t)\n",
    "\t\t\t#print(\"{} updated plan\".format(t))\n",
    "\n",
    "\t\t\t#M = self.modify_plan(G, M,t)\n",
    "\t\t\t#print(\"{} modified plan\".format(t))\n",
    "\n",
    "\t\t\tself.execute_plan(ongoing_instance, resource_set, M, t)\n",
    "\t\t\t#print(\"{} executed plan\".format(t))\n",
    "\n",
    "\t\t\tcompletes = self.update_completes(completes, ongoing_instance, t)\n",
    "\n",
    "\t\t\t#print('current completes: {}'.format(len(completes)))\n",
    "\n",
    "\t\t\t# for log generation\n",
    "\t\t\t#for i in ongoing_instance:\n",
    "\t\t\t#\tcost_dict = dict()\n",
    "\t\t\t#\tfor j in i.get_pred_act_dur_dict().keys():\n",
    "\t\t\t#\t\tweight = i.get_weight()\n",
    "\t\t\t#\t\t#j.set_duration_dict(i,pred_dur)\n",
    "            #        pred_dur = i.get_pred_act_dur(j)\n",
    "\t\t\t#\t\tpred_dur += max([i.get_next_pred_ts()-t, j.get_next_pred_ts()-t, 0])\n",
    "\t\t\t#\t\tcost = int(pred_dur / weight * 10)\n",
    "\t\t\t#\t\tcost_dict[j] = cost\n",
    "\t\t\t#\tprint(\"ongoing {} - status: {}, next: {}, cost: {}\".format(i.get_name(),i.get_status(), i.get_next_actual_act(),cost_dict))\n",
    "\n",
    "\t\t\tt+=1\n",
    "\t\t\tif t > 2500:\n",
    "\t\t\t\t#print(\"STOP\")\n",
    "\t\t\t\tbreak\n",
    "\t\ttime2 = time.time()\n",
    "\n",
    "\t\ttotal_weighted_sum = sum(self.w_comp_time)\n",
    "\t\ttotal_pred_time = sum(self.pred_time)\n",
    "\t\ttotal_computation_time = (time2-time1)\n",
    "\t\ttotal_opti_time = total_computation_time - total_pred_time\n",
    "\n",
    "\t\tprint(\"total weighted sum: {}\".format(total_weighted_sum))\n",
    "\t\tprint('suggested algorithm took {:.1f} s'.format(total_computation_time))\n",
    "\t\tprint(\"total time for predictions: {:.1f} s\".format(total_pred_time))\n",
    "\t\tprint(\"total time for optimizations: {:.1f} s\".format(total_opti_time))\n",
    "\t\twith open(\"./exp_result/{}.txt\".format(exp_name), \"w\") as f:\n",
    "\t\t\t#f.write(f\"Test path: {test_path}, \\nAlpha: {alpha},\\nBeta: {beta},\\nTotal Weighted Sum: {total_weighted_sum},\\nTotal Computation Time: {total_computation_time},\\nTotal Prediction Time: {total_pred_time},\\nTotal Optimitation Time: {total_opti_time},\\nPrecision (in%): {self.precision*100}\")\n",
    "\t\t\tf.write(f\"Total Weighted Sum: {total_weighted_sum},\\nTotal Computation Time: {total_computation_time},\\nTotal Prediction Time: {total_pred_time},\\nTotal Optimitation Time: {total_opti_time}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6be311-d7d4-4576-abf7-2b37e98e8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates = ['2012-03-01', '2012-03-03', '2012-03-04', '2012-03-05', '2012-03-06', '2012-03-07', '2012-03-08', '2012-03-09', '2012-03-10', '2012-03-11', '2012-03-12', '2012-03-13', '2012-03-14', '2012-03-15']\n",
    "dates = ['2012-03-10']\n",
    "org_log_path = 'sample_data/real/modi_BPI_2012_dropna_filter_act.csv'\n",
    "alpha = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14118660-42ca-4d8a-b0c7-3b167f134c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@timefn: assign_caseid took 0.014050960540771484 seconds\n",
      "@timefn: assign_activity took 0.0072672367095947266 seconds\n",
      "@timefn: assign_resource took 0.01855945587158203 seconds\n",
      "%Y.%m.%d %H:%M:%S\n",
      "@timefn: assign_timestamp took 0.012141704559326172 seconds\n",
      "@timefn: assign_caseid took 0.0009226799011230469 seconds\n",
      "@timefn: assign_activity took 0.0008108615875244141 seconds\n",
      "@timefn: assign_resource took 0.0006461143493652344 seconds\n",
      "%Y.%m.%d %H:%M:%S\n",
      "@timefn: assign_timestamp took 0.002019643783569336 seconds\n",
      "8647 exceed the limit\n",
      "8564 exceed the limit\n",
      "8479 exceed the limit\n",
      "9491 exceed the limit\n",
      "9491 exceed the limit\n",
      "9491 exceed the limit\n",
      "8135 exceed the limit\n",
      "8857 exceed the limit\n",
      "9104 exceed the limit\n",
      "8004 exceed the limit\n",
      "9574 exceed the limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [54:26<00:00, 3266.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total weighted sum: 1658\n",
      "suggested algorithm took 3266.8 s\n",
      "total time for predictions: 3261.0 s\n",
      "total time for optimizations: 5.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for date in tqdm(dates):\n",
    "    Opt = SuggestedOptimizer()\n",
    "    testp =  f\"sample_data/real/modi_BPI_2012_{date}.csv\"\n",
    "    exp_name = 'suggested_' + date\n",
    "    Opt.main(org_log_path = org_log_path, test_path  =testp, mode='real', alpha=alpha, beta=alpha, precision=0.0, date=date, exp_name=exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "389c23dd-d0e0-4e78-9711-985af4accfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728aef5-ab28-407d-ba46-197509892935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
